<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>T-CONV</title>
    <url>/2021/03/17/T-CONV/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>T-CONV</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<a id="more"></a>

<p>在本文中，我们提出了将轨迹建模为二维图像的T-CONV，并采用多层卷积神经网络结合多尺度轨迹模式以实现精确的预测。此外，我们进行梯度分析以可视化T-CONV捕获的多尺度空间模式，并提取对最终预测有明显影响的区域。最后，我们整合了多个局部增强卷积场，以深入探索这些重要领域，以进行更好的预测。</p>
<p><strong>传统的目的地预测</strong>：最近提出的一些模型通过使用马尔可夫模型将查询轨迹与历史记录相匹配来预测目的地，或者根据运动对象的轨迹聚类并根据相似对象的移动性模式进行预测。</p>
<ol>
<li>为了进行准确的预测，T-CONV将轨迹建模为二维图像，并采用多层卷积神经网络来组合多尺度二维轨迹特征。与传统的一维轨迹模型相比，T-CONV更清晰，更有效地捕获了不同空间尺度上的二维局部模式。</li>
<li>为了可视化T-CONV捕获的多尺度模式，分析了特征的梯度分布，结果表明T-CONV可以在其较低的卷积层中有效地学习小规模的轨迹模式，并且将它们组合成更高层次的大规模模式。可视化还显示，靠近输入轨迹的起点和终点的部分对其最终目的地的预测有明显的影响。</li>
<li>除了对整个输入轨迹进行卷积以外，我们还进一步在T-CONV中集成了多个局部增强卷积场，以进一步探索轨迹图像中的特定重要区域，这不仅可以减少轨迹数据集中的稀疏性问题，而且还可以大大提高了预测的准确性。</li>
</ol>
<h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>对于出租车$T_i$而言，轨迹序列可以表示为<br>$$<br>\zeta_{i,j} = &lt;\delta_{i,j,1},\delta_{i,j,2},…,\delta_{i,j,N_{i,j}}&gt;<br>$$</p>
<p>$$<br>\delta_{i,j,k} = (\Phi_{i,j,k},\Upsilon_{i,j,k})(1\leq k \leq N_{i,j})<br>$$</p>
<p>其中$\Phi_{i,j,k},\Upsilon_{i,j,k}$代表经纬度</p>
<p>预测问题：给定出租车$T_i$以及对应的轨迹$\zeta_{i,j}$得到最终的目的地$\Theta(\zeta_{i,j})$</p>
<h2 id="多尺度下的轨迹区别"><a href="#多尺度下的轨迹区别" class="headerlink" title="多尺度下的轨迹区别"></a>多尺度下的轨迹区别</h2><p><img src="https://i.loli.net/2021/03/17/sPLr5UKDAO6wlgX.png" alt="image-20210130135911999"></p>
<p>轨迹也具有显着的多尺度属性：在不同的空间尺度中，轨迹可以表现出不同的二维模式。图2显示了不同比例的滑行轨迹的典型示例。虚线表示从标有“ O”的位置开始行驶的滑行车的轨迹$\zeta_{i,j}$。图中的其他轨迹是训练集中的历史轨迹。图2（a）显示了最高分辨率的原始轨迹。<br>当处理不同比例的轨迹时，网格是将地图划分并将属于同一像元的空间点合并为一个不可分割的单元的常用工具。图2（b）显示了具有密集网格的微观空间尺度，其中以精细的粒度记录了轨迹。在这种比例下，轨迹视图显示了其运动模式的大多数细节，并且轨迹的重叠度很低，这在执行轨迹匹配时会导致稀疏性问题。当我们将地图划分为稀疏网格时，我们可以在更大的空间比例上说明轨迹，如图2（c）所示。在这种规模下，轨迹的重叠增加，并且移动物体的整体趋势更易于捕获。轨迹被分为两个类，根据这些类，出租车的目的地很有可能看起来像是“ x”。</p>
<h2 id="模型部分"><a href="#模型部分" class="headerlink" title="模型部分"></a>模型部分</h2><p>对于路网进行划分为$M*M$的网格，其中一网格记作$C_{m,n}$，对于其中一轨迹来说网格的数值可以记作<br>$$<br>I_{i,j}(m,n) = \begin{cases} 0, &amp;\text{if } \not\exists \delta_{i,j,k}(\delta_{i,j,k} \in \zeta_{i,j}  \and \delta_{i,j,k}\vartriangleright C_{m,n}) \ 1, &amp;\text{if}\delta_{i,j,N_{i,j}} \vartriangleright C_{m,n} \ 0.5 ，&amp;\text{otherwise}\end{cases}<br>$$</p>
<p>基于设置的T-CONV的模型为</p>
<p><img src="https://i.loli.net/2021/03/17/HDnRY4kd1eXzJlN.png" alt="image-20210130140704357"></p>
<p>即利用多层CNN进行提取特征后，利用softmax函数进行分类，后提取特征后进行计算概率。</p>
<p><strong>梯度可视化</strong></p>
<p>对于相关的特征贡献，采用梯度的方式进行可视化的展示<br>$$<br>g(k,c,m,n,x,y) = \frac{\part F_{c,m,n}^{(k)}}{\part I(x,y)}<br>$$</p>
<p>图4（b）显示了层L2可以捕获小规模模式，这些模式集中在小局部区域的详细变化上。同时，图4（a）示出了较高层L 4可以将较低级别的小规模图案组合成较大规模的有效图案。此外，图4中的红色和粗体区域对应于较大的渐变，并指示图案中的重要部分。从图4（a）中，有趣的是，经过训练的T-CONV模型可以“识别”出靠近轨迹起点和终点的局部区域对目的地预测的贡献更大。直觉上，轨迹的末端部分很重要，因为它最靠近目的地，并且揭示了轨迹的最新趋势。同时，轨迹的开始部分也很重要，因为它表明了客户来自何处，并代表了旅行的一些内在动机。</p>
<p><img src="https://i.loli.net/2021/03/17/3MN7BptVf9RnyjG.png" alt="image-20210130141637195"></p>
<h2 id="局部增强模型"><a href="#局部增强模型" class="headerlink" title="局部增强模型"></a>局部增强模型</h2><p>基于观察到轨迹的起点和终点附近的局部部分对目的地预测起着更为重要的作用，我们可以对这些局部区域进行深层卷积，而不必在全局图像上进行卷积。下图显示了该模型的体系结构，该模型集中于以输入轨迹的起点和终点为中心的两个局部区域。</p>
<p><img src="https://i.loli.net/2021/03/17/BXnfoLWVYcTba6z.png" alt="image-20210130142016008"></p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>测量这些模型的评估误差是实际目的地与预测位置之间的Haversine距离。距离定义为：<br>$$<br>d(x,y) = 2·r·arctan(\sqrt{\frac{a}{1-a}})<br>$$<br><img src="https://i.loli.net/2021/03/17/TBn7gQvZrb5RCXH.png" alt="image-20210130142414497"></p>
<h2 id="总结和展望部分"><a href="#总结和展望部分" class="headerlink" title="总结和展望部分"></a>总结和展望部分</h2><p>该文采用了多尺度的CNN的方式，从而对于不同尺度的特征进行分别提取，结合额外信息获取最终的预测目的地。</p>
<p>并且基于此的基础上提出了局部增强的方式。</p>
<p>总的来说，对于目的点的预测是对于轨迹模式相似性的探索，文中通过CNN的方式对这种特征进行提取。</p>
<p><strong>问题</strong>：</p>
<ol>
<li><p>能否通过将CNN置换成GCN的方式进行进一步的提取（多尺度GCN能否解决</p>
</li>
<li><p>数据的方式采用的是格网还是正常道路路段方式</p>
</li>
<li><p>数据是否存在稀疏问题</p>
</li>
<li><p>ETA嵌入部分</p>
</li>
</ol>
<p>对于ETA部分，ETA的估计涉及到相关的空间信息、时间信息以及相关的轨迹信息，能否在该模块中进行相关的嵌入</p>
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>论文笔记</tag>
        <tag>深度学习</tag>
        <tag>目的点预测</tag>
      </tags>
  </entry>
  <entry>
    <title>从Arcgis编码说开来</title>
    <url>/2021/01/11/%E4%BB%8EArcgis%E7%BC%96%E7%A0%81%E8%AF%B4%E5%BC%80/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>神说：选UTF-8</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<a id="more"></a>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前段时间，遇见了如下的两个问题</p>
<ol>
<li>power shell安装oh-my-posh后显示为方块</li>
<li>ArcGIS通过csv转换得到的point shapefile的属性信息同地理坐标发生错位</li>
</ol>
<p>  而最终对于上述两个问题的解决，其问题的本质均指向了编码问题，同样也是在平时编写代码过程中最为重要但同时也即为容易被忽略的问题，下面如何解决上述问题以及就编码这一概念展开解释。</p>
<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><h3 id="编码本质"><a href="#编码本质" class="headerlink" title="编码本质"></a>编码本质</h3><p>  日常代码过程中遇见的绝大部分的乱码问题都可以归结到编码问题，而编码的本质其实就是对于给计算机的一本<strong>字典</strong>，即编码实现了如下两件事情</p>
<ol>
<li>给所有字符一个独一无二的数字编号，通过mapping的机制进行一一映射，如我将”00000001”映射给”蔡”这一中文字符</li>
<li>该数字编号能用0、1表示</li>
</ol>
<p>  对于2而言，由于编码的长度存在不定长的情况，如’才’映射给”00000010”,而”菜”用”00000001 00000010”，而计算机如何分辨读取到的编码应该映射为“蔡才”还是“菜”便成了问题。（常见的UTF-8编码中的中文常为3-4个字节），而对于第二个问题的解决一般是采用<strong>定长</strong>的策略，即规定多少字节的代表一个字符，对于<strong>未达到长度的字符前面补0</strong>进行解决。</p>
<h3 id="乱码的背后机理"><a href="#乱码的背后机理" class="headerlink" title="乱码的背后机理"></a>乱码的背后机理</h3><p>  说起乱码对于大部分人影响最为深刻的应该为C以及C++命令行输出“烫烫烫”或者“屯屯屯”的乱码形式，其输出如下乱码的原因是VS studio部分的编辑器对于未分配的内存空间会默认填入相关的内容。</p>
<ol>
<li><p>未分配或者静态分配而未赋初值的内存采用0xCC填充</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> C; <span class="comment">// default C = -858993460(0xCCCCCCC)</span></span><br><span class="line">	   <span class="comment">// 烫（0xCCCC）</span></span><br></pre></td></tr></tbody></table></figure></li>
<li><p>动态分配(new, malloc)而未赋初值的内存采用0xCD填充，其中屯(0xCDCD)</p>
</li>
</ol>
<p>  由上述例子我们可以发现乱码的本质就是<strong>编码解码采用了不同的标准</strong>。</p>
<p>  对于计算机而言计算机只能识别0/1进制数据，这就决定了我们需要实现一下两种过程</p>
<p><strong>编码</strong>：文字符号 $\to$ 二进制数据</p>
<p><strong>解码</strong>：二进制数据 $\to$ 文字符号</p>
<p>  如下为将字符串先进行utf-8编码，再利用gbk解码，最终输出的结果即为乱码</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">s = <span class="string">"蔡菜菜"</span></span><br><span class="line">s.encode(<span class="string">'utf-8'</span>).decode(<span class="string">'gbk'</span>,errors=<span class="string">'ignore'</span>) <span class="comment">#‘ignore’ 去除非gbk框架内的字符</span></span><br><span class="line"><span class="comment"># output s = '钄¤彍鑿'</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="字体和编码"><a href="#字体和编码" class="headerlink" title="字体和编码"></a>字体和编码</h3><p>  从上面可以得知，不同的编码体系主要实现的内容是<strong>字符编码</strong>同<strong>二进制存储码</strong>之间转换的不同体系的“字典”，而字体库即是对于字符编码的可视化显示过程的字典，所以文字调用的过程可以解释为下列流程</p>
<ol>
<li>根据计算机提供的二进制数据，在确定的编码体系中（如UTF-8)，转换为目标的<strong>文字编码</strong></li>
<li>根据文字编码同程序中设置的文字样式（如Mono)等，提取出字体库中的目标符号进行展示</li>
</ol>
<p>  所以字体库的主要目的是在于美观。同样的由于不同字体库能表示的文字符号是有限的，对于<strong>不在库中的文字同样是无法显示出正确的符号</strong>，而这部分符号的显示常常会用一些默认的符号（如方块）进行替换。</p>
<h3 id="中文编码"><a href="#中文编码" class="headerlink" title="中文编码"></a>中文编码</h3><p><img src="https://pic4.zhimg.com/80/v2-0d0285e7b9433eeedf7e705d6e082d13_720w.jpg" alt="img"></p>
<p>  常见的中文编码兼容性图如上，可见 GB18030 $\to$ GBK $\to$ GB2312 $\to$ ASCII $\leftarrow$ UTF8。UTF8同GB相关的中文字符除了ASCII有一定交集外没有任何的交集。这也是最为常见导致乱码的场景，UTF8同GBK的编解码混用。</p>
<p>  ASCII编码是最为常见的编码形式，但其能编码的字母和符号仅用128个，其能被大部分的编码体系兼容（除UTF-16，UTF32）</p>
<h4 id="GB18030-to-GBK-to-GB2312"><a href="#GB18030-to-GBK-to-GB2312" class="headerlink" title="GB18030 $\to$ GBK $\to$ GB2312"></a>GB18030 $\to$ GBK $\to$ GB2312</h4><p>  GB即国标，GBK即国标扩展，这三种编码的本质除了字节长度的不同，本质上都是前者对于后者由于汉字数目需要的扩展。</p>
<ol>
<li><strong>GB2312</strong></li>
</ol>
<p>  最先提出的兼容中文字符的编码集，其最先提出是在ASCII的基础上进行扩展，每个字占据了<strong>2bytes</strong>，同时输入法常见的半角全角的概念（全角即英文的字符长度同汉字等宽），而全角同半角的相同英文字符背后的编码是不同的（全角输入导致编辑器无法运行的原因）</p>
<ol start="2">
<li><strong>GBK</strong></li>
</ol>
<p>  在GB2312的基础上进一步扩展了GB2312的6312个中文字符至20902个，同时添加了中文标点符号部首等等</p>
<ol start="3">
<li><strong>GB18030</strong></li>
</ol>
<p>  在GBK字符基础上进一步扩展，但是由于2bytes的存储上限仅为65536，所以GB18030每个字节占据了<strong>4bytes</strong>。</p>
<p>具体的字节值域见下图，由于需要兼容ASCII所以第一个8bits的最高位置为0</p>
<p><img src="https://pic1.zhimg.com/80/v2-905e6e4840050444f64375ffd9dffc48_720w.jpg" alt="img"></p>
<p>同时需要注意的是上述中文编码均采用了<strong>定长编码的划分方式</strong></p>
<h4 id="UTF-8"><a href="#UTF-8" class="headerlink" title="UTF-8"></a>UTF-8</h4><p>  我对于UTF-8的初印象是来自于，对于大部分python2不兼容中文一般的解决方法通过在文件首通过设定为UTF-8进行解决。UTF-8编码的出现是为了能解决世界上的大部分文字，也是目前大部分代码过程中会采用的编码形式。其的主要目的便是将<strong>Unicode（字符集）</strong>设定一一映射的<strong>编码规则</strong>。</p>
<p>  但UTF-8为变长字符编码，这也是导致了其同GB系列的编码除ASCII外的所有均不兼容的主要原因。</p>
<p>  UTF-8采用了二进制<strong>最高位连续1的个数</strong>来决定该字是几字节编码（如110xxxxx代表的为双字节，同时这也意味着前n+1位是间隔判断字符），如果最高位为0则代表单字节（该举措是为了兼容ASCII编码）。如下图即为汉字字符从Unicode字符集中转换为UTF-8的过程。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e65b436e01c4df151e496bf2acfab51c_720w.jpg" alt="img"></p>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><h3 id="power-shell-oh-my-posh"><a href="#power-shell-oh-my-posh" class="headerlink" title="power shell oh-my-posh"></a>power shell oh-my-posh</h3><p>  oh-my-posh类似于linux系统中的oh-my-zsh主要作用是对于命令行的美化，但对于oh-my-posh设置后往往会出现方块问题（该问题同样在WSL的oh-my-zsh中存在），问题示意如下图。</p>
<p><img src="https://i.loli.net/2021/01/11/VUDqMnbuxjXyJ7i.png"></p>
<p>  由上述可知，出现方块的字符的主要原因是，字体库中不支持该字符编码导致的问题，具体的解决方案如下。</p>
<p>  下载并安装<a href="https://github.com/ryanoasis/nerd-fonts%E5%86%85%E7%9A%84%E5%AD%97%E4%BD%93%E5%B9%B6%E8%BF%9B%E8%A1%8C%E5%AE%89%E8%A3%85%EF%BC%8C%E5%B0%86%E5%86%85%E9%83%A8%E7%9A%84%E5%AD%97%E4%BD%93%E8%AE%BE%E7%BD%AE%E6%9B%B4%E6%8D%A2%E4%B8%BA%E5%AE%89%E8%A3%85%E7%9A%84%E5%AD%97%E4%BD%93%E3%80%82%E7%BB%93%E6%9E%9C%E5%A6%82%E4%B8%8B%E6%89%80%E7%A4%BA%E3%80%82">https://github.com/ryanoasis/nerd-fonts内的字体并进行安装，将内部的字体设置更换为安装的字体。结果如下所示。</a></p>
<p><img src="https://i.loli.net/2021/01/11/nqEsWi17Rdj58Lh.png"></p>
<p>解决问题的核心在于nerd-fonts提供的字体库能提供相应所需的符号。</p>
<h3 id="Arcgis错位问题"><a href="#Arcgis错位问题" class="headerlink" title="Arcgis错位问题"></a>Arcgis错位问题</h3><p>  解决该部分的问题将近用了两天时间，下列主要是对于解决的过程和相关的方法进行总结。</p>
<h4 id="问题本质"><a href="#问题本质" class="headerlink" title="问题本质"></a>问题本质</h4><p>  该问题的产生同样是因为编码问题导致，而这一问题是我利用python进行逐行写入后编码问题报错，从而意识到了所谓的错位问题本质是在于编码方式导致的直接问题。在对于逐行编码过程中，发现不管是采用<strong>GB</strong>系列亦或者是<strong>UTF-8</strong>均会产生无法编码的字符，这就表明了，原始数据中存在<strong>不同编码方式</strong>的数据，而Arcgis采用统一的编码形式进行编码，也就导致了该问题的发生。</p>
<p>​  同时需要注意的是，ArcGIS打开dBase文件时，会先对于.CPG文件进行读取，确定编码类型，如果缺失CPG文件，则Arcgis会默认将编码假设为Windows(ANSI/Multi-byte)，这也是导致dbf属性表乱码的原因之一。</p>
<h4 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h4><p>  确定了问题是由于数据中存在不同形式的编码形式，但python的pandas读取数据后均为二进制的存储方式（python的str存储的为二进制码），所以为了解决编码不统一的问题主要采用了下列代码。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">s = <span class="string">"目标语句"</span></span><br><span class="line">s = s.encode(<span class="string">'utf-8'</span>,errors=<span class="string">'ignore'</span>).decode(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># errors ignore剔除了同utf-8无法表示的内容符号，并最后解码成utf-8的方式进行存储</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="核心相关代码"><a href="#核心相关代码" class="headerlink" title="核心相关代码"></a>核心相关代码</h4><p>  该部分主要介绍了csv等文件转换为shapefile的两种方式，以下代码均为核心代码。</p>
<ol>
<li><strong>geopandas</strong></li>
</ol>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> geopandas <span class="comment"># geopandas的方式，具体安装流程参照https://blog.csdn.net/weixin_38333199/article/details/101761810</span></span><br><span class="line">df= gpd.read_file(<span class="string">r'company_final_data.xlsx'</span>,encoding=<span class="string">'utf-8'</span>) <span class="comment"># 读取文件</span></span><br><span class="line">df[[<span class="string">'pointx'</span>,<span class="string">'pointy'</span>]] = df[[<span class="string">'pointx'</span>,<span class="string">'pointy'</span>]].apply(pd.to_numeric) </span><br><span class="line">gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.pointx, df.pointy))<span class="comment"># 添加点位置</span></span><br><span class="line">gdf.crs = pyproj.CRS.from_user_input(<span class="string">'EPSG:4326'</span>) <span class="comment">#给输出的shp增加投影</span></span><br><span class="line">gdf.to_file(<span class="string">'test.shp'</span>,</span><br><span class="line">           driver=<span class="string">'ESRI Shapefile'</span>,</span><br><span class="line">           encoding=<span class="string">'utf-8'</span>) <span class="comment"># 写入shapefile文件</span></span><br></pre></td></tr></tbody></table></figure>
<ol start="2">
<li>pyshp</li>
</ol>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> shapefile <span class="comment"># pip install pyshp</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_shapefile</span>(<span class="params">shape_path, csv_data</span>):</span></span><br><span class="line">    file = shapefile.Writer(shape_path, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment">#创建字段 C字符 100字符长度， N 双精度 D 日期</span></span><br><span class="line">    colunms_list = csv_data.keys()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        file.field(colunms_list[i],<span class="string">'C'</span>,<span class="string">'100'</span>)</span><br><span class="line">    file.field(colunms_list[<span class="number">3</span>], <span class="string">'D'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>):</span><br><span class="line">        file.field(colunms_list[i+<span class="number">4</span>], <span class="string">'C'</span>, <span class="string">'100'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        file.field(colunms_list[i+<span class="number">19</span>], <span class="string">'N'</span>, <span class="string">'31'</span>, decimal=<span class="number">4</span>)</span><br><span class="line">    <span class="comment"># 读取csv每行文件进行逐一赋值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(csv_data[<span class="string">'企业名称'</span>]))):</span><br><span class="line">        <span class="keyword">if</span> csv_data[<span class="string">'lon'</span>].values[i] == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 添加点矢量</span></span><br><span class="line">        file.point(csv_data[<span class="string">'lon'</span>].values[i], csv_data[<span class="string">'lat'</span>].values[i])</span><br><span class="line">        <span class="comment"># 添加属性表的记录</span></span><br><span class="line">        file.record(<span class="built_in">str</span>(csv_data[<span class="string">'企业名称'</span>].values[i]).encode(<span class="string">'gbk'</span>,errors=<span class="string">'ignore'</span>).decode(<span class="string">'gbk'</span>).encode(<span class="string">'utf-8'</span>).decode(<span class="string">'utf-8'</span>), </span><br><span class="line">                  <span class="comment">#省略不细写</span></span><br><span class="line">                   csv_data[<span class="string">'lon'</span>].values[i],</span><br><span class="line">                   csv_data[<span class="string">'lat'</span>].values[i])</span><br><span class="line">            </span><br><span class="line">    file.close()</span><br><span class="line">    <span class="comment"># 定义投影</span></span><br><span class="line">    proj = osr.SpatialReference() </span><br><span class="line">    proj.ImportFromEPSG(<span class="number">4326</span>) <span class="comment"># 4326-GCS_WGS_1984; 4490- GCS_China_Geodetic_Coordinate_System_2000</span></span><br><span class="line">    wkt = proj.ExportToWkt()</span><br><span class="line">    <span class="comment"># 写入投影</span></span><br><span class="line">    f = <span class="built_in">open</span>(shape_path.replace(<span class="string">".shp"</span>, <span class="string">".prj"</span>), <span class="string">'w'</span>) </span><br><span class="line">    f.write(wkt)<span class="comment">#写入投影信息</span></span><br><span class="line">    f.close()<span class="comment">#关闭操作流</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://zhuanlan.zhihu.com/p/46216008">https://zhuanlan.zhihu.com/p/46216008</a></p>
<p><a href="https://github.com/ryanoasis/nerd-fonts">https://github.com/ryanoasis/nerd-fonts</a></p>
<p><a href="https://blog.csdn.net/weixin_38333199/article/details/101761810">https://blog.csdn.net/weixin_38333199/article/details/101761810</a></p>
]]></content>
      <categories>
        <category>代码杂记</category>
      </categories>
      <tags>
        <tag>编码</tag>
        <tag>python</tag>
        <tag>gis</tag>
      </tags>
  </entry>
  <entry>
    <title>烟火</title>
    <url>/2021/03/11/%E7%83%9F%E7%81%AB/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>烟火</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<a id="more"></a>

<p><img src="https://pic2.zhimg.com/v2-242297ad8b1316e8336cbe5dd009770c_r.jpg?source=1940ef5c"></p>
<h2 id="起"><a href="#起" class="headerlink" title="起"></a>起</h2><p>  从恐怖游戏角度来说，烟火并不是沿用着西方恐怖游戏的口味——僵尸、恶鬼、转角杀、核能手电筒，不是说西式恐怖游戏不不恐怖，作为市场的主力来说，这样的恐怖口味是被大部分游戏玩家所能接受的，但是这不是属于中式的恐怖游戏，近年来也只有某不能说的台湾游戏公司的两部作品可以说得上是具有中式恐怖口味的。</p>
<p>  国内说起恐怖，绕不过的是十八层地狱、奈何桥上的孟婆汤，可以说国内的鬼怪风水之说是有文化依托的，如果仅仅是通过游戏的恐怖氛围营造，通过“转角遇见爱”这一手法引起的玩家肾上腺素升高的做法，其实仅仅是建立在人类的生理反应这一大前提之上的，所以如何将作为恐怖符号的文化嵌入到游戏中才是如何做好一个中式恐怖游戏的大前提。</p>
<p>  但如果仅仅是文化的嵌入，又略显单薄，所以烟火同前辈们的选择都是一致，去尝试揭露藏在恐怖这一表面下的具有悲剧意味的故事，因为比起文化符号，符号下的人情味也是现如今社会的一大特质，而作为故事的核心是否经得起推敲，是否能引人共情，才是决定着这个游戏的高度。</p>
<p>  毫无疑问，烟火是一款及其出色的游戏，因为其的故事内核、人物塑造是近几年游戏中难见的优秀。</p>
<h2 id="承"><a href="#承" class="headerlink" title="承"></a>承</h2><p>  故事中人物塑造是否成功在我看来最为关键的点就是人物前后的行为逻辑是否让人感觉到了割裂感，比如一个大恶人突然告诉观众他改悔了开始乐于助人了，这就是割裂，行为逻辑上是先天带着矛盾的。而烟火仅四小时的流程，描述的所有角色是不存在割裂的，这也得益于脸谱化的人物，脸谱化人物可以说得上是自带贬义色彩的词汇，所以导致了很多故事为了能让角色更加“丰满”，将一堆矛盾的特质赋予这一人物，这种行为就同在钢丝上舞蹈，处理不好就是万丈深渊。但烟火并不顾及这一点，可以说它将人物的行为理念是固定死的，但是并不妨碍角色的自身的耀眼。</p>
<p>  同《钢炼》中的greed，可以说是天生的反面人物，坚持的唯一理念就是greed，最后的慷慨赴死却会让人感觉到惋惜。烟火中的所有人物都会有一个很明确的理念。支撑着林理洵的就是那一句“你要为死人申冤”，陈老师则是小时候掉进井中往上爬的满天星辰，叶医生的是想挣脱鸟笼的理想，赵小娟脚注这是那句“我的尸体,不会腐烂在泥土里,我会像鸟儿一样,死在天空中”，即使是作为剧中反派的田家夫妇也是有着儿子这一命门。所以所有的角色在剧中的行为都是完全合乎情理的，同样也正是这样的合乎情理才造成了最后的田家惨案，同时也造就了烟火般璀璨的结局。</p>
<p>  单纯的从游戏的角度出发，烟火的解密其实说不上十分出色，但是可以说很好的完成了对于游戏剧情过度的粘合剂，而我想聊的是烟火这款游戏的画面。烟火的恐怖方式的设置是具有中式特点的，纸人、棺材、红烛是具有浓厚的中式氛围的，但更加戳动我的是地狱那一段的剧情，奈何桥，一艘纸船横渡奈何，所见景象为地狱景象，所见为代父受刑。这一剧情的设置是具有很明显的文化符号，相近的如短片《十八层地狱》，而且不不仅仅是生硬的嵌入，是极具剧情张力的。<br><img src="https://pic4.zhimg.com/v2-2cd05382d410fa775447e91e19452708.jpg?source=1940ef5c"></p>
<h2 id="转"><a href="#转" class="headerlink" title="转"></a>转</h2><p>  烟火，绽放的时候是满天星辰，而熄灭的时候是飘落于天空黑色的灰尘，可能如此的灰尘堆满了这连绵的大山，堆成了一座枷锁，让叶医生深陷其中，而身为主角的林理洵，也停在了梦中的路边，慢慢目送父亲的远去，但陈老师呢，生死未知，但我还是由衷的希望，她登上了那艘船，在另一个井中让更多的孩子能望见更多的繁星。<br><img src="https://pic1.zhimg.com/v2-ebb0a506cfd14beed58d21ebb08df493_r.jpg?source=1940ef5c"></p>
<h2 id="合"><a href="#合" class="headerlink" title="合"></a>合</h2><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>长亭外 古道边 芳草碧连天，<br>晚风拂柳笛声残 夕阳山外山，<br>长亭外 古道边 芳草碧连天，<br>晚风拂柳笛声残 夕阳山外山，<br>天之涯 地之角 知交半零落，<br>一壶浊酒尽余欢今宵别梦寒，<br>长亭外 古道边 芳草碧连天，<br>问君此去几时来 来时莫徘徊，<br>天之涯 地之角 知交半零落，<br>人生难得是欢聚 惟有别离多，<br>天之涯 地之角 知交半零落，<br>人生难得是欢聚 惟有别离多</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<p><img src="https://pic4.zhimg.com/v2-fb9cf58ed9fd8b8340c6271e1eb8c2be_r.jpg?source=1940ef5c"></p>
<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p><a href="https://www.bilibili.com/video/BV1rb411N7ck">https://www.bilibili.com/video/BV1rb411N7ck</a><br><a href="https://store.steampowered.com/app/1288310/_/">https://store.steampowered.com/app/1288310/_/</a></p>
]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>恐怖游戏</tag>
      </tags>
  </entry>
  <entry>
    <title>空间数据分析</title>
    <url>/2021/01/19/%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>简单来说，就是一次作业</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<a id="more"></a>
<p>  本文主要是对于武汉二环内的出租车路段对之间的转移流量的数据进行分析，并基于数据分析的相关结果利用相关的预测模型进行路段转移流的预测，并对不同模型的结果进行对比。</p>
<h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>  本文研究的路段对转移流量即，相邻路段之间的目标出租车的转移流量过程，如下面示意图所示。</p>
<p><img src="https://i.loli.net/2021/01/19/4eDzVSOI6FcBZ2o.jpg" alt="问题示意"></p>
<p>  如上图所示，A路段的邻接路段为B，C，D，即研究其的转移路段为为A-B，A-C，A-D（注：本文仅考虑地理空间一阶相邻的路段对流量）。</p>
<p><strong>相关变量定义</strong></p>
<p>  $G = (V,E)$：表示整体的路网结构，其中$V = {v_1,v_2,…v_n}$代表图中的节点，具体到现实即为路段。$E$表示节点之间的边缘流，其中定义$e_{ij} \in E$而$e_{ij}$为节点$v_i \to v_j$的边。</p>
<p>  由于本文仅仅考虑相邻的路段对，所以对于$E$集合中的非邻接对的数值固定为0，所以可将问题重新简化为。</p>
<p>  定义：$E_t = {e^t_1, e^t_2,…,e^t_n}$，其中$e_i^t$表示为在$t$时刻的第$i$条边的流量值。</p>
<p>  预测目标：$E_t = f(E_{t-1},E_{t-2},…,E{t-n})$，即通过$t-1,t-2,…t-n$的数据预测得到$t$时刻的数据。</p>
<h2 id="实验数据"><a href="#实验数据" class="headerlink" title="实验数据"></a>实验数据</h2><h3 id="数据说明"><a href="#数据说明" class="headerlink" title="数据说明"></a>数据说明</h3><p>  本次研究武汉二环路网结构如下述所示，共计4136条路段。</p>
<p><img src="https://i.loli.net/2021/01/19/auNxlqYiAwknrKF.png"></p>
<p>  本文实验采用的数据为武汉市2017.07.03-2017.07.30共计四个星期的轨迹数据，数据示意如下图所示，每天约有600个轨迹点数据。</p>
<p><img src="https://i.loli.net/2021/01/19/3MOHvexrQGtDKZz.png"></p>
<p>  其中TaxiID为出租车编号，Date数据时间，streetMID为匹配的路段。</p>
<h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><h4 id="空间数据处理"><a href="#空间数据处理" class="headerlink" title="空间数据处理"></a>空间数据处理</h4><p>  该部分主要是对于目标路网的空间数据处理，其主要目的根据路网的数据提取出路网中相邻路段邻接对，主要采用了arcgis的网络分析功能，提取出邻接道路，存储结构如下。</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>Src_MID_Street</th>
<th>Dst_MID_Street</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>1008</td>
<td>1065</td>
</tr>
</tbody></table>
<p>  其中Src_MID_Street为路段对的起始路段，Dst_MID_Street为路段对的目标路段，处理得到共计18734对路段对。</p>
<h4 id="轨迹数据处理"><a href="#轨迹数据处理" class="headerlink" title="轨迹数据处理"></a>轨迹数据处理</h4><p>  该部分主要是针对于将轨迹数据转换为路段对流量的数据处理过程，以下为处理过程中需要注意的内容部分。</p>
<ol>
<li>路段转移流的定义，当同一辆出租车(Taxi ID)在研究的时间间隔内发生了(streetMID)的变化时候，该路段对的转移流量增加一。</li>
<li>实际场景考虑，出租车可能会发生$A \to B \to C$的过程，但实际记录点仅存在$A,C$两点，此时需要引入最短路径算法，本文采用了的为Dijkstra算法，求取$path = Dijkstra(i,j)$通过$path$进行转移流量的计算。</li>
</ol>
<p>具体的算法过程如下</p>
<p><img src="https://i.loli.net/2021/01/19/5GnMkr7uCZje6AU.png"></p>
<h2 id="数据相关分析"><a href="#数据相关分析" class="headerlink" title="数据相关分析"></a>数据相关分析</h2><p>  本文对于上述得到的数据主要分为两个部分进行分析，一部分为时间序列上的数据的分析，一部分为空间上的数据的分析。</p>
<h3 id="时间序列分析"><a href="#时间序列分析" class="headerlink" title="时间序列分析"></a>时间序列分析</h3><p><strong>周期性分析</strong></p>
<p>  周期性分析主要是对于单一路段对的时间序列的分析，以及总体流量的数据分析，结果如下所示。（其中流量的时间聚合粒度设置为10分钟）</p>
<p><img src="https://i.loli.net/2021/01/19/93KUaTch6ItpZJD.png" alt="离散性"></p>
<p>  上图为其中一路段对07-03—07-16的流量波动情况，可见没有明显的周期性，但整体数值偏低。</p>
<p><img src="https://i.loli.net/2021/01/19/TKB5iHhYREgOecd.png" alt="周期性"></p>
<p>  上图为其中一路段对07-03—07-16的流量波动情况，可以明显看出其呈现出以天为单位的周期性特征。</p>
<p><img src="https://i.loli.net/2021/01/19/swOHIQfTKAXPBRa.png" alt="流量总和"></p>
<p>  上图为总体流量的流量波动可视图，可见其也呈现出明显的以天为单位的波动情况，且高值点出现的时间点为凌晨0-1点以及早上的9-10点范围。</p>
<p>  综上所述，研究范围内的路段对流量，当该路段对较为活跃（即任意时段都有较高的流量）时，呈现出明显的周期性特征。而消极路段对则没有上述特征。但就整体而言，仍然呈现出明显的周期性特征，对于采用相关的时间序列预测有一定的支撑性。</p>
<p><strong>时间序列自相关</strong></p>
<p>  时间序列自相关（autocorrelation or lagged correlation）用于评估时间序列数据是否依赖于其过去的数据。</p>
<p>  本文对于总流量时间序列进行了自相关序列，lag为10分钟，且使用了2016个lag进行计算。</p>
<p><img src="https://i.loli.net/2021/01/19/JgPk7jXlwR61Zma.png" alt="自相关系数"></p>
<p>  见图可知目标点之间的相关性程度可知分别为current(即lag 10minutes)，day(即lag 1440 minutes)，hour(即lag 60minutes)三种序列情况，该点也是支撑下述模型对比中是否采用三种时间间隔序列权重融合的方式可以获取更高的精确度。</p>
<h3 id="空间相关性分析"><a href="#空间相关性分析" class="headerlink" title="空间相关性分析"></a>空间相关性分析</h3><p>  根据地理学第一定律而言，距离越近的地理事物相关性越高，此处主要是对于该种观点的验证，相邻的路段对之间是否仍然会存在空间上的相关性。</p>
<p>  主要采取的方法为计算空间自相关性，（空间相关性即证明，数据是否同空间分布相关）此处引进了局部莫兰指数进行评估。</p>
<p><strong>局部Moran‘s I</strong><br>$$<br>I_i = \frac{Z_i}{S^2}\sum^n_{j \neq i} w_{ij}Z_j<br>$$<br>其中，$Z_i = y_i - \bar{y}, Z_j = y_j - \bar{y}, S^2 = \frac{1}{n}\sum(y_i - \bar{y})^2$</p>
<p>  其中根据计算得到的结果可以分为以下四个区域。</p>
<img src="https://i.loli.net/2021/01/19/h3iFTwqMvjVKQHY.png" alt="局部莫兰指数示意" style="zoom:67%;">

<p>  本文对流量对进行了局部莫兰指数计算（属性为流量），结果如下述所示。</p>
<img src="https://i.loli.net/2021/01/19/aYUlyzwAv3GWu8x.png" alt="局部莫兰空间图" style="zoom:80%;">

<p>  上图中，红色代表高度正相关，蓝色代表负相关，灰色为无明显相关关系。（该图的转移对采用的为路段中点相连的方式，该图会在后文中采用D3方式的可视化进行改进）</p>
<p><img src="https://i.loli.net/2021/01/19/vLGDfhmXPZdOWi2.png" alt="局部莫兰结果图"></p>
<p>如上图所示，$R^2 = 0.56$具有较为明显的正相关关系。</p>
<p>  由上述内容可知，路段对在空间中也存在的明显的相关性，该点也是后续中引入ST-ResNet对比的前置条件。</p>
<h2 id="模型对比"><a href="#模型对比" class="headerlink" title="模型对比"></a>模型对比</h2><p>  为了验证上述根据数据分析得到的相关内容，本文通过对于下述三个模型：GRU模型、Multi-GRU模型，ST-ResNet模型进行预测结果的对比，并对于最后的结果进行可视化分析。</p>
<h3 id="对比模型说明"><a href="#对比模型说明" class="headerlink" title="对比模型说明"></a>对比模型说明</h3><p><strong>GRU模型</strong>：传统的深度学习时间序列模型，模型结构如下图所示</p>
<img src="https://img-blog.csdnimg.cn/20200102180123857.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2plc3NleXVsZQ==,size_16,color_FFFFFF,t_70#pic_center" alt="GRU" style="zoom:67%;">

<p>  本文仅选取目标时间点$t$之前的${t-T,t-T + 1,…,t-1}$对结果进行预测。</p>
<p><strong>Multi-GRU模型</strong>： 多时间序列模型融合的GRU模型</p>
<p>  模型的基本单元同上述的GRU模型一致，不同的是采用了多个时间序列的预测后进行加权融合的过程。</p>
<p>Current Sequence： ${t- T, t-T+1, …,t-1}$</p>
<p>Hour Sequence：${t-hour_T, t-hour_{t-1},…,t-hour_1}$<br>Day Sequence：${t-day_T, t-day_{t-1},…,t-day_1}$</p>
<p>  最后预测的结果表示为：$P’ = w_1P’_{current} + w_2P’_{hour} + w_3P’_{day}$</p>
<p><strong>ST-ResNet模型</strong>：结合空间信息的深度残差模型</p>
<p><img src="https://github.com/snehasinghania/STResNet/raw/master/assets/st-resnet.png" alt="ST-ResNet"></p>
<p>  该模型为 <a href="https://arxiv.org/abs/1610.00081">“Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction”</a>. 一文中提出的空间残差模型，其能较好地捕获空间信息同时间信息。</p>
<h3 id="对比模型结果"><a href="#对比模型结果" class="headerlink" title="对比模型结果"></a>对比模型结果</h3><p>本次实验采用的对比指标为$MSE$<br>$$<br>MSE = \sum^n_{j=1}(\hat{y_j} - y_j)^2<br>$$<br><img src="https://i.loli.net/2021/01/19/uCVwc1tU6AHbl7D.png" alt="对比图"></p>
<p>如上图所示，可以支撑先前对于数据分析的结论</p>
<ol>
<li>引进多序列的方式能提高模型的预测精度</li>
<li>对于空间信息的引入同样能提高对于模型的预测精度</li>
</ol>
<h3 id="结果可视化"><a href="#结果可视化" class="headerlink" title="结果可视化"></a>结果可视化</h3><p>  传统的采用上图的可视化的实际效果一般，所以本文采用了D3框架对于转移流进行了进一步的可视化操作。</p>
<p><strong>主要实现的思路：</strong></p>
<p>1.获取道路上的目标的比例点(0.7)</p>
<p>2.根据转移流的关系，将比例点通过曲线(贝塞尔曲线)连接</p>
<p>3.对于不同的属性划分不同的等级，赋予不同的颜色以及线段的粗细</p>
<p><img src="https://i.loli.net/2021/01/19/AcjqHLxJyohY5te.png" alt="真实流量图"></p>
<p>上图为真实流量的结果可视化图</p>
<p><img src="https://i.loli.net/2021/01/19/kRE4ynuZxG8HJch.png" alt="预测结果图"></p>
<p>上图为预测流量的结果可视化图</p>
<p><img src="https://i.loli.net/2021/01/19/MrXA9Jgl3v2Gkwm.png" alt="误差图"></p>
<p>上图为预测同目标之间的误差的结果可视化图</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>  本文旨在对于武汉路段对转移流量的数据分析以及可视化，同时结合分析的相关结果利用三种模型进行比对，很好的支撑了文章中数据分析得出的相关的结论即多时间序列以及空间信息对于预测的模型起到了一定的作用。同时在最后利用了D3这一可视化框架，对于结果进行了可视化展望。</p>
<p>  但本文中对于空间信息的提取仅停留在最为初级的地步，如何更好的利用上述的空间信息更好的促进预测，是之后进一步研究的工作重点。</p>
]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>空间数据</tag>
        <tag>预测</tag>
        <tag>交通</tag>
      </tags>
  </entry>
  <entry>
    <title>阿加莎的推理王国</title>
    <url>/2021/01/13/%E9%98%BF%E5%8A%A0%E8%8E%8E%E7%9A%84%E6%8E%A8%E7%90%86%E7%8E%8B%E5%9B%BD/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>有人生来就被幸福拥抱，有人生来就被长夜围绕。</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<a id="more"></a>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>  阿婆的推理成就在此我不多赘述，“侦探女王”四个字的分量足以体现一切。也许阿婆的推理小说以今天的眼光来看是重诡计设计而轻人物设计的，其大部分小说的人物更像是为诡计所服务的“工具人”。除此之外，阿婆的部分小说是具有较为明显的同质性，以我的角度进行叙述便是“移动式的密室案件”——虽然大部分的案件都是发生了场景的变换，但是究其根本，人物都是在阿婆精心构建的一个小世界内发生的案件，这也导致了同质化的发生（此点在ABC谋杀案中尤为明显）。</p>
<p>​  欲扬先抑，虽然列举了种种阿婆推理小说的问题，但一切都不能跳脱时代背景来说，对于那个推理小说刚以一种文学形式进入世界后，阿婆无疑称得上是和柯南道尔并列的双子星。即使脱离时代来看，对于初次接触推理小说的读者来说，阿婆的推理小说也是一块极佳的敲门砖。不仅仅是体现于在小说中掺杂的独属于阿婆女性的那一份细腻，也体现于阿婆所开创的属于推理小说经典的诡计设计。</p>
<h2 id="书籍及介绍"><a href="#书籍及介绍" class="headerlink" title="书籍及介绍"></a>书籍及介绍</h2><p>​  以下为我个人对于阿婆推理小说的推荐，仅仅阐述推荐的级别及理由，但不对剧情进行介绍（推理的乐趣在于对后续剧情强烈的好奇心）★☆</p>
<h3 id="《东方快车谋杀案》"><a href="#《东方快车谋杀案》" class="headerlink" title="《东方快车谋杀案》"></a>《东方快车谋杀案》</h3><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>不可能的事不可能已经发生，因此不可能的事尽管看起来不可能，但肯定有可能发生。</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>推荐指数：★★★★★</p>
<p>​  东方快车谋杀案无疑是阿婆推理小说的首选，不断的被电影化也足见其的优秀。不仅仅是对于整个诡计的设计，同样你能感受到波洛作为“人”这一形象的丰满，不再是常见的更偏向于“神”的侦探形象，这一案件引起的是对于犯罪这一本身是否善恶的思考，从而表达出波洛仅仅是更聪明的“人”，而不是洞穿一切的“神”。</p>
<p>  吐槽一句：东方快车谋杀案的犯罪形式是目前剧本杀的一大创作方式，但大部分的剧本杀仅仅流于这个诡计手法的表面，却没有指向其中的内核，东方快车谋杀案中的犯人是因为“爱”而彼此包庇的，而侦探同样是因为“爱”而选择了放弃真相（真相近乎是侦探的生命）</p>
<h3 id="《罗杰疑案》"><a href="#《罗杰疑案》" class="headerlink" title="《罗杰疑案》"></a>《罗杰疑案》</h3><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>习惯会束缚人的手脚。我们努力工作只为了那么一个目标，如愿以偿之后，却又开始怀念日复一日的劳碌生活。</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>推荐指数：★★★★★</p>
<p>  叙述者诡计开创先河者，这一句话已经奠定了这本小说的地位。不幸的，由于《冰菓》的缘故提前了解到这一手法，导致四分之三的阅读已经得出了凶手是谁这一结论，导致后续的阅读体验有所下降。但对于未接触过叙述者诡计这一手法的读者，在我看来，罗杰疑案是阿婆推理技法的巅峰，是一本能给读者带来推理小说中逐渐抽丝剥茧的推理乐趣。</p>
<h3 id="《三幕悲剧》"><a href="#《三幕悲剧》" class="headerlink" title="《三幕悲剧》"></a>《三幕悲剧》</h3><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>一个把自己戏剧化的男人，有时会被看错。别人不会认真对待他的真心。</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>推荐指数：★★★☆</p>
<p>  One，Two，Three，阿婆设计的极具戏剧表达张力的一场演出，前面的悲剧是为了最后一幕高潮悲剧的提前预演，整部诡计的设计可以说是从一定程度上参照了戏剧。能让身为读者的我，成为坐在舞台前的一位观众，欣赏的是舞台上的三幕悲剧，但问题还是出现于那一句“重诡计而轻人物”，除了波洛这位常驻侦探外没有任何能立于我心中的角色。</p>
<h3 id="《死亡约会》"><a href="#《死亡约会》" class="headerlink" title="《死亡约会》"></a>《死亡约会》</h3><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>有时候我们妥协，是害怕争吵。争吵是让人很不舒服的事情。但是我想，行动的自由是值得我们为之奋斗的东西。</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>推荐指数：★★★★</p>
<p>​  戏剧质感，这是我对于阿婆大部分书的第一观感。死亡约会的诡计设计优秀程度同三幕悲剧可以说是不相上下的，而多出来的半星，是阿婆在这本书中的体现出来的人文主义关怀以及角色塑造要优于三幕悲剧。虽然书名是具有悲剧色彩的，但是结尾却显得足够温馨，也见阿婆对于爱情这一美好事物的追求。只是对于美好的追求已经开始呈现出对于诡计叙述的压倒导致结尾的观感有些许遗憾。</p>
<h3 id="《闪光的氰化物》"><a href="#《闪光的氰化物》" class="headerlink" title="《闪光的氰化物》"></a>《闪光的氰化物》</h3><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>Rosemary is to help people recall. </p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>推荐指数：★★★☆</p>
<p>​  闪光的氰化物，可以称得上是阿婆对于错综复杂的人物关系的一次很大胆的尝试，不同于其余书的隐藏人物关系，这本书将这种隐藏在人物背后的关系进一步打乱、打结，引向了更加进一步的复杂，并且诡计的设计完全是基于这一人物关系上，诡计本身并不复杂，但通过这一人物关系将原本简单的诡计引向了一种混沌的状态，如同被猫玩后的毛线球，无法找到真正的线头是在何处。但存在的问题同三幕悲剧一样，极强的写作技巧和诡计设计但是及其微弱的人物存在。</p>
<h3 id="《ABC谋杀案》"><a href="#《ABC谋杀案》" class="headerlink" title="《ABC谋杀案》"></a>《ABC谋杀案》</h3><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>可是经常被称作是直觉的事物，其实是一种以逻辑推理结论或经验为基础的印象。 </p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>推荐指数：★★☆<br>  ABC谋杀案说得上是阿婆在大众出镜率较高的一本书（点名冰菓），但如果要推荐的话，我仅仅推荐给刚开始接触阿婆小说的读者，对于已经读过阿婆较多作品的人来说这一本会让人产生直接的审美疲劳。虽然是全国各地发生的凶杀案件，也是极为经典的预言式杀人（比如非自然死亡就是借鉴了这一诡计的设计），但本质上逃脱不了我开头说的移动式密室，而这一点在这显示的更为严重，场景的更换，但是不更换的是参与这一案件的人员，换句话说将受害人、侦探、凶手放进一个密室，然后按照顺序逐一发生凶杀案，营造出来的效果同这也相差无几，唯一区别的是场景更大后能营造出一种“史诗感”。但对我而言，读到这本书后面让我产生了少见的“告诉我真相，我不想和波洛一起破案了”的对于推理小说来说的消极情绪。</p>
<h3 id="《尼罗河上的惨案》"><a href="#《尼罗河上的惨案》" class="headerlink" title="《尼罗河上的惨案》"></a>《尼罗河上的惨案》</h3><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>人生空幻。 一点爱情， 一点仇恨， 还有互道早安。 人生短暂。 一点希望， 一点梦想， 还有互道晚安。</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>推荐指数：★★★★☆</p>
<p>​  “尼罗河上的惨案值得四星半”，我如是说到。原因在于这本书在死亡约会中我提及的人物塑造更近一步，即使到现在我也能回忆起书中塑造的人物形象是如何的，而不仅仅是因为诡计的精妙让我记住了这些角色，是因为这些角色的本身让我记住了这些角色。<br>  回到诡计，也是阿婆小说中天花板级别的设计，华丽的不在场证据的设计——不仅仅是因为诡计需要设计如此的不在场证明，在这不在场证明的背后是存在感情上的逻辑链条。可以说比起早先的一些作品的重诡计来说，阿婆开始向着人这一本身的塑造改变（这一点在之后的长夜中进入了我所认为的巅峰），阿婆追求的可能不仅仅是死亡约会中的美好，而是对于悲剧进一步的思考。对于我而言读完后最大的问题在于，男主为什么要留下那个所谓的“佐罗印记”，当然答案是不言而喻的。</p>
<h3 id="《无人生还》"><a href="#《无人生还》" class="headerlink" title="《无人生还》"></a>《无人生还》</h3><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>十个小兵人，外出去吃饭。一个被呛死，还剩九个人。九个小兵人，熬夜熬得深。一个睡过头，还剩八个人。八个小兵人，动身去德文。一个要留下，还剩七个人……</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>推荐指数：★★★★★</p>
<p>​  无人生还是阿婆目前深受英国本土喜爱的作品之一，戏剧电影的改编不计其数。之所以放在此处讲，是因为这一本是脱离了波洛探案集的推理小说，同样也是阿婆作品中绕不过的一部作品，作为压轴刚好合适。无人生还的诡计展现形式接近于ABC谋杀案的形式，同样是预告式杀人，但是不同的是无人生还更加富有戏剧性，甚至可以称上是阿婆所有作品中的戏剧演出的巅峰。<br>  十个人一个小岛，一首英国的古老童谣，每个人背后的故事、罪恶，在一场场死亡中被赎罪，不难相信为什么这部作品成为了戏剧电影改编的常客。一座孤岛上的死亡镰刀，一群人接受的审判，从头到尾一出好戏。</p>
<h3 id="《长夜》"><a href="#《长夜》" class="headerlink" title="《长夜》"></a>《长夜》</h3><p>推荐指数：★★★★★</p>
<p>​  之所以将长夜放在这个位置，仅仅是长夜是我最爱的阿婆的作品之一，同上述几本书不同，是阿婆很少见的未着重于诡计设计的作品，而是完完全全通过了人物性格的塑造去推动剧情的发生，单纯的就诡计而言可以说是不出彩的，但是就整本书而言这样的诡计是恰到好处的。如同在20世纪50年代在日本出现的社会派推理，长夜这一本书完全可以归于那一派别。</p>
<p>​  长夜这一故事的构思上可以窥见许多作品的影子，手法是借鉴《罗杰疑案》的叙述者诡计，富家女同落魄男子的恋爱，也在阿婆的小说中频繁出现如《尼罗河上的惨案》，更确切地说这甚至是看房人之谜的扩展。但往更遥远的历史回溯，甚至同爱伦坡笔下的《泄密的心》《黑猫》等的剧情走向颇为相似，本质上来说，阿婆在晚年时间更加深切的去剖析了人性，写出了一场颇让人悲伤的戏剧。虽然阅读这本书已过了许久，但让人难忘的艾丽在那个阳光的午后，在梦想的别墅中弹奏的那曲歌谣</p>
<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>人生有喜悦，也有悲怜。</p>
<p>看透了这一点，才能安然走过世间。</p>
<p>每一个夜晚，每一个清晨，有人生来就为不幸伤神。</p>
<p>每一个清晨，每一个夜晚，有人生来就被幸福拥抱。</p>
<p>有人生来就被幸福拥抱，有人生来就被长夜围绕。</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>  只不过艾丽爱上了一个被长夜围绕的人，一个用自己的欲望吞噬了周围所有人的人。</p>
]]></content>
      <categories>
        <category>书评</category>
      </categories>
      <tags>
        <tag>读书记录</tag>
        <tag>推理</tag>
        <tag>阿加莎</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN交通领域论文汇总</title>
    <url>/2021/03/17/T-GCN/</url>
    <content><![CDATA[<a id="more"></a>
<h1 id="GCN-A-Temporal-Graph-ConvolutionalNetwork-for-Traffic-Prediction"><a href="#GCN-A-Temporal-Graph-ConvolutionalNetwork-for-Traffic-Prediction" class="headerlink" title="GCN: A Temporal Graph ConvolutionalNetwork for Traffic Prediction"></a>GCN: A Temporal Graph ConvolutionalNetwork for Traffic Prediction</h1><h2 id="methodology"><a href="#methodology" class="headerlink" title="methodology"></a>methodology</h2><h3 id="problem-Definiton"><a href="#problem-Definiton" class="headerlink" title="problem Definiton"></a>problem Definiton</h3><ol>
<li><p>road network: $G = (V,E)$,描述道路网络的拓扑结构 </p>
<p>adjancency matrix:$A \in R^{N \times N}$ 描述邻接矩阵之间的关系</p>
</li>
<li><p>feature matrix: $X^{N \times P}$ 描述节点的特征数矩阵</p>
<p>$X_t \in R^{N \times i}$  代表在i时刻的路段速度</p>
</li>
</ol>
<p>问题：在G的拓扑结构的前提下，通过前一段时间的特征预测下一段时间的特征问题</p>
<p>$[X_{t+1}, …, X_{t+T}] = f(G;(X_{t-n},…,X_{t-1}, X_t)$</p>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>T-GCN = GCN + GRU</p>
<ol>
<li>n time内的历史数据，作为输入，其中gcn捕捉道路得拓扑结构</li>
<li>将空间特征输入GRU模型，获取时间特征，最后通过全连接层得到结果</li>
</ol>
<p><img src="https://i.loli.net/2021/03/17/yf5HOajZWvIRPEn.png" alt="image-20200820005656918"></p>
<h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Spatial-Dependence-Modeling"><a href="#Spatial-Dependence-Modeling" class="headerlink" title="Spatial Dependence Modeling"></a>Spatial Dependence Modeling</h3><p>$$f(X,A) = \sigma(\hat{A} Relu(\hat{A}XW_0)W_1)$$</p>
<p>$X$：特征矩阵</p>
<p>$\hat{A}$：空间特征提取过程</p>
<p>$W_0,W_1$: 两层的权重矩阵</p>
<h3 id="Temporal-Dependence-Modeling"><a href="#Temporal-Dependence-Modeling" class="headerlink" title="Temporal Dependence Modeling"></a>Temporal Dependence Modeling</h3><p><img src="https://i.loli.net/2021/03/17/hALpW61igKvDxIE.png" alt="image-20200820200012908"></p>
<p>采用了GRU模型</p>
<p>$h_{t-1}$： 隐藏状态</p>
<p>$x_t$：t时刻的交通信息</p>
<p>$r_t$：重置门</p>
<p>$u_t$：更新门</p>
<p>$c_t$：当前时间交通信息的存储</p>
<h3 id="Temporal-Graph-Convolutional-Network"><a href="#Temporal-Graph-Convolutional-Network" class="headerlink" title="Temporal Graph Convolutional Network"></a>Temporal Graph Convolutional Network</h3><p><img src="https://i.loli.net/2021/03/17/HMeIcmKDiA6uCQ7.png" alt="image-20200820200019712"></p>
<p>$u_t = \sigma(W_u[f(A,X_t),h_{t-1}] + b_u)$</p>
<p>$r_t = \sigma(W_r[f(A,X_t),h_{t-1}] + br)$</p>
<p> $c_t = tanh(W_c[f(A,X_t),(r_t*h_{t-1})] + b_c)$</p>
<p>$h_t = u_t* h_{t-1} + (1-u_t)*c_t$</p>
<h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>$loss = ||Y_t - \hat{Y_t}|| + \lambda L_{reg}$</p>
<p>为了防止过拟合引入了L2正则化项</p>
<h1 id="GCN-GAN-A-Non-linear-Temporal-Link-Prediction-Model-for-Weighted-Dynamic-Networks"><a href="#GCN-GAN-A-Non-linear-Temporal-Link-Prediction-Model-for-Weighted-Dynamic-Networks" class="headerlink" title="GCN-GAN: A Non-linear Temporal Link Prediction Model for Weighted Dynamic Networks"></a>GCN-GAN: A Non-linear Temporal Link Prediction Model for Weighted Dynamic Networks</h1><p>GCN-GAN网络处理对于权重动态网络的link-prediction任务</p>
<h2 id="Problem-definition"><a href="#Problem-definition" class="headerlink" title="Problem definition"></a>Problem definition</h2><p>$G = {G_1,G_2,…,G_\tau}$</p>
<p>$G_t = (V,E_t,W_t)$</p>
<p>其中研究对象的图均为无向图，且节点一致（不产生新节点）</p>
<p>$A_t \in R^{|V| \times |V|}$ 描述邻接矩阵的静态空间结构，同时令$(A_t)_{ij} = (A_t)_{ji} = W_t{i,j}$</p>
<p><strong>任务描述</strong>：即通过${A_{\tau-l},A_{\tau-l+1},…,A_\tau}$，预测$A_{\tau+1}$</p>
<p>$\tilde{A}<em>{\tau+1} = f(A</em>{\tau-1},A_{\tau-l+1}…, A_\tau)$</p>
<h2 id="Methodology-1"><a href="#Methodology-1" class="headerlink" title="Methodology"></a>Methodology</h2><p>结构图</p>
<p><img src="https://i.loli.net/2021/03/17/9NLz3ufYZOr5tnd.png" alt="image-20200906203119640">i) Graph Convolutional Network</p>
<p>ii) Long Short-Term Memory</p>
<p>iii) Generative Adversarial Nets(GAN)</p>
<ol>
<li>通过GCN获取本地的图的拓扑结构</li>
<li>利用GCN获取得到的图信息，作为LSTM的输入</li>
<li>通过全连接的判别网络进行动态网络的预测</li>
</ol>
<h3 id="The-GCN-Hidden-Layer"><a href="#The-GCN-Hidden-Layer" class="headerlink" title="The GCN Hidden Layer"></a>The GCN Hidden Layer</h3><p>$X = GCN(Z,A) = f(\hat{D}^{-1/2}\hat{A}\hat{D}^{-1/2}ZW), A\in R^{N \times N}, Z\in R^{N \times M}$</p>
<p>其中$Z$为顶点的特征矩阵，$\hat{A} = A +I_N$ </p>
<h3 id="The-LSTM-Hidden-Layer"><a href="#The-LSTM-Hidden-Layer" class="headerlink" title="The LSTM Hidden Layer"></a>The LSTM Hidden Layer</h3><p>介绍LSTM的细节</p>
<h3 id="The-Generative-Adversarial-Network"><a href="#The-Generative-Adversarial-Network" class="headerlink" title="The Generative Adversarial Network"></a>The Generative Adversarial Network</h3><p>为了解决动态网络边缘权重的稀疏性和宽值范围问题</p>
<p>$min_Gmax_D (E_{x\sim p_{data}x}[logD(x)] +E_{z\sim p_z}[1-D(G_z)])$</p>
<p>其中$x$作为训练集的输入数据，$z$代表由一确定的可能性分布$p(z)$噪声生成</p>
<p>a) The Discriminative Network D</p>
<p>将$G$的输出$\tilde{A}<em>{\tau+1}$和真实数据$A</em>{\tau+1}$一维化后作为输入</p>
<p>$D(A’) = (\sigma(a’W_h^D+ b_h^D)W_o^D + b_o^D)$</p>
<p>需要将$A_{\tau+1}$进行归一化</p>
<p>b) The Generative Network G</p>
<p>GCN中将$A^\tau_{\tau-1}$以及噪声Z作为输入，其中$Z \sim U(0,1)$</p>
<p>$\tilde{A}<em>{\tau+1} = G(Z,A^\tau</em>{\tau-l})$通过逆过程获取最终的预测结果</p>
<h3 id="Model-Optimization"><a href="#Model-Optimization" class="headerlink" title="Model Optimization"></a>Model Optimization</h3><p>预训练过程更新G的相关参数</p>
<p>loss function: $min_{\theta_G}h(\theta_G;Z,A^{\tau-1}<em>{\tau-l-1},A_\tau) = ||A_\tau-G(Z,A^{\tau-1}</em>{\tau-l-1})||_F^2 + \lambda/2 ||\theta_G||^2_2$</p>
<p>利用梯度下降更新D的相关参数</p>
<p>loss function: $min_{\theta_D}h_D(\theta_D;D,A^{\tau-1}<em>{\tau-l-1},A_\tau) = E[D(A_\tau)] - E[D(G(Z,A^{\tau-1}</em>{\tau-l-1}))]$</p>
<p>对于D更新完之后，利用D的参数更新G</p>
<p>loss function: $min_{\theta_G}h(\theta_G;Z,A^{\tau-1}<em>{\tau-l-1}) = -E[D(G(Z,A^{\tau-1}</em>{\tau-l-1}))]$</p>
<h1 id="A3T-GCN-Attention-Temporal-Graph-Convolutional-Network-for-Traffic-Forecasting"><a href="#A3T-GCN-Attention-Temporal-Graph-Convolutional-Network-for-Traffic-Forecasting" class="headerlink" title="A3T-GCN: Attention Temporal Graph Convolutional Network for Traffic Forecasting"></a>A3T-GCN: Attention Temporal Graph Convolutional Network for Traffic Forecasting</h1><p>T-GCN的改进模型引入了注意力的相关机制</p>
<h3 id="Attention-Model"><a href="#Attention-Model" class="headerlink" title="Attention Model"></a>Attention Model</h3><p>采用 soft attention 模型，学习每个时刻交通信息的重要性，产生context vector 可以表示交通状况全局变化趋势</p>
<p>suppose：$x_i(i=1,2,…)$表示$i$时刻的时间序列</p>
<ol>
<li>通过CNNs/RNNs计算不同时刻的隐藏状态$h_i(i=1,2,…n)$</li>
<li>设计scoring function 计算每个隐藏层的得分/权重</li>
<li>attention function· 计算context vector($C_t $)来描述交通全局变量信息</li>
<li>使用context vector 获取最终的结果</li>
</ol>
<p>$$e_i = w_{(2)}(w_{(1)}H + b_{(1)}) + b_{(2)} $$ 标注：公式有问题 正确表达应该是$E = w_{(2)}(w_{(1)}H + b_{(1)}) + b_{(2)}$其中$E = (e_1,e_2,…e_n)$</p>
<p>$\alpha_i = \frac{exp(e_i)}{\sum^n_{k=1}exp(e_k)}$</p>
<p>其中$\alpha_i$表示每个特征的权重，通过归一化计算获得</p>
<p>$C_t = \sum^n_{i=1}\alpha_i * h_i$</p>
<h3 id="AT3-GCN-Model"><a href="#AT3-GCN-Model" class="headerlink" title="AT3-GCN Model"></a>AT3-GCN Model</h3><p><img src="https://i.loli.net/2021/03/17/8iZcpAYFknSaEKC.png" alt="image-20200913210128356"></p>
<p>GCN 计算得到的隐藏状态作为注意力模型的输入</p>
<h1 id="Adaptive-Graph-Convolutional-Recurrent-Network-for-Traffic-Forecasting"><a href="#Adaptive-Graph-Convolutional-Recurrent-Network-for-Traffic-Forecasting" class="headerlink" title="Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting"></a>Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting</h1><h2 id="Methodology-2"><a href="#Methodology-2" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h3><p>multi-step traffic forecasting problem</p>
<p>$\mathcal{X} = {X_{:,0},X_{:,1},…X_{:,t},…}$</p>
<p>$X_{:,t} = {x_{1,t},x_{2,t},…x_{i,t}…,x_{N,t}}^T$ 代表的是$t$时刻的特征合集</p>
<p>target：${X_{:,t+1},X_{:,t+2},…X_{:,t+\tau}} = \mathcal{F}<em>\theta(X</em>{:,t},X_{:,t-1},….,X_{:,t-T+1};\mathcal{G})$</p>
<h3 id="Node-Adaptive-Parameter-Learning"><a href="#Node-Adaptive-Parameter-Learning" class="headerlink" title="Node Adaptive Parameter Learning"></a>Node Adaptive Parameter Learning</h3><p>GCN可以很好的被近似为一阶Chebyshev 多项式展开，生成的高维的GCN可以表示为</p>
<p>$Z = (I_N + D^{-1/2}AD^{-1/2})X\Theta + b$</p>
<p>从单个Node的角度来说，GCN的本质可以看成从$X^i \in R^{1\times C} \to Z^i \in R^{1\times F}$，在所有节点共享 $\Theta$以及$b$</p>
<p>sharing parameter可以有效的减少参数数量。对于道路预测问题，道路之间的联系是一个动态的模式，所以传统的GCN不是最佳的解决方案，两个相邻的节点在不同的时刻由于不同的因素产生出来的模式也不尽相同。</p>
<p>对于$\Theta \in R^{N \times C \times F}$来说，当$N$过大时难以近似甚至会导致过拟合问题。</p>
<p>GCN 结合 节点自适应参数学习模型</p>
<p>NAPL学习两个小参数据矩阵</p>
<ol>
<li><p>a node-embedding matrix $E_{\mathcal{G}} \in R^{N\times d}$, 其中$d$是代表embedding dimension，其中$d &lt;&lt; N;2$</p>
</li>
<li><p>权重池$W_{\mathcal{G}} \in R^{d\times C \times F}$,其中$\Theta = E_{\mathcal{G}}·W_{\mathcal{G}}$，从单个节点($i$)的角度来说，相当于是根据node embedding $E_{\mathcal{G}}^i$从整个共享权重池$W_{\mathcal{G}}$中提取参数$\Theta^i$</p>
<p>$Z = (I_N + D^{-1/2}AD^{-1/2})XE_{\mathcal{G}}W_{\mathcal{G}} + E_{\mathcal{G}}b_{\mathcal{G}}$</p>
<p>从改进公式来看，主要是将学习全局的过程，拆分为每个节点的embedding dimension内的参数的学习，能防止参数学习的过拟合问题等。</p>
</li>
</ol>
<h3 id="Data-Adaptive-Graph-Generation"><a href="#Data-Adaptive-Graph-Generation" class="headerlink" title="Data Adaptive Graph Generation"></a>Data Adaptive Graph Generation</h3><p>针对于邻接矩阵$A$的定义，传统方式可以分为两种 1）  距离函数，根据节点之间的物理距离进行定义 2）根据计算节点之间的相似度进行定义</p>
<p>提出<strong>Data Adaptive Graph Generation</strong>，从数据推断隐藏的相互关系。</p>
<ol>
<li><p>对每个节点定义了一个可学习节点嵌入字典，$E_A \in R^{N\times d_e}$，其中$d_e$定义了节点嵌入的维数，根据节点的相似度定义</p>
<p>$D^{-1/2}AD^{-1/2} = softmax(ReLU(E_A·E^T_A))$</p>
</li>
<li><p>$E_A$不断的更新，从而显示不同交通信息序列的隐藏关系，来得到图卷积的邻接关系</p>
<p>$Z = (I_N + softmax(ReLU(E_A · E_A^T)))X\Theta$</p>
</li>
</ol>
<p>时间部分采用了GRU的模型架构</p>
<h1 id="Attention-Based-Spatial-Temporal-Graph-Convolutional-Networks-for-Traffic-Flow-Forecasting"><a href="#Attention-Based-Spatial-Temporal-Graph-Convolutional-Networks-for-Traffic-Flow-Forecasting" class="headerlink" title="Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting"></a>Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting</h1><h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><h3 id="Traffice-Networks"><a href="#Traffice-Networks" class="headerlink" title="Traffice Networks"></a>Traffice Networks</h3><p>$G = (V,E,A)$，$V$代表节点数目，$E$代表节点之间的连通性，$A \in \Bbb{R}^{N \times N}$ 代表G的邻接矩阵</p>
<h3 id="Traffic-Flow-Forecasting"><a href="#Traffic-Flow-Forecasting" class="headerlink" title="Traffic Flow Forecasting"></a>Traffic Flow Forecasting</h3><p>$x^{c,i}_t \in \Bbb{R}$代表node-$i$，在时间$t$的第$c$个feature</p>
<p> $X_t = (x_t^1,x_t^2,…,x_t^N)^T \in \Bbb{R}^{N\times F}$在$t$时刻的节点的所有特征</p>
<p>$\mathcal{X} = (X_1,X_2,…X_\tau)^T \in \Bbb{R}^{N\times F \times \tau}$代表在$\tau$时间切片上所有节点的所有特征</p>
<p>$y_t^i = x^{f,i}_t \in \Bbb{R}$代表节点$i$在时间$t$时刻的流量</p>
<p><strong>Problem</strong>：给定$\mathcal{X}$，预测未来的流量序列$Y = (y^1,y_2,…y^N)^T \in \Bbb{R}^{N\times T_p}$</p>
<p>其中$y^i = (y_{\tau+1}^i,y_{\tau+2}^i,…,y_{\tau+T_p}^i) \in \Bbb{R}^{T_p}$</p>
<h2 id="Attention-Based-Spatial-Temporal-Graph-Convolutional-Networks"><a href="#Attention-Based-Spatial-Temporal-Graph-Convolutional-Networks" class="headerlink" title="Attention Based Spatial-Temporal Graph Convolutional Networks"></a>Attention Based Spatial-Temporal Graph Convolutional Networks</h2><p><img src="https://i.loli.net/2021/03/17/L31qBfnYUjolwZc.png" alt="image-20200915095136063"></p>
<ol>
<li><p>The recent segmen</p>
<p>$\mathcal{X}<em>h = (X</em>{t_0-T_h + 1},X_{t_0-T_h + 2},….X_{t_0}) \in \Bbb{R}^{N\times F \times T_h}$</p>
</li>
<li><p>The daily-periodic segment </p>
<p>$\mathcal{X}<em>d = (X</em>{t_0 - (T_d/T_p)*q + 1},…,X_{t_0 - (T_d/T_p)*q + T_p},X_{t_0 - (T_d/T_p-1)*q + 1},…X_{t_0 - (T_d/T_p-1)*q + T_p}…X_{t_0 - q + 1},…X_{t_0 - q + T_p}) \in \Bbb{R}^{N\times F \times T_d}$</p>
</li>
<li><p>The weekly-periodic segment</p>
<p>$\mathcal{X}<em>w = (X</em>{t_0 - 7*(T_w/T_p)<em>q + 1},…,X_{t_0 - 7</em>(T_w/T_p)<em>q + T_p},X_{t_0 -7</em> (T_w/T_p-1)<em>q + 1},…X_{t_0 - 7</em>(T_w/T_p-1)<em>q + T_p}…X_{t_0 -7</em> q + 1},…X_{t_0 -7* q + T_p}) \in \Bbb{R}^{N\times F \times T_w}$</p>
</li>
</ol>
<p><img src="https://i.loli.net/2021/03/17/wEbqIJLA4FclVZN.png" alt="image-20200915100716655">\</p>
<h3 id="Spatial-Temporal-Attention"><a href="#Spatial-Temporal-Attention" class="headerlink" title="Spatial-Temporal Attention"></a>Spatial-Temporal Attention</h3><h4 id="Spatial-attention"><a href="#Spatial-attention" class="headerlink" title="Spatial attention"></a>Spatial attention</h4><p>空间注意力部分</p>
<p>$S = V_s · \sigma((\mathcal{X}_h^{(r-1)}W_1)W_2(W_3\mathcal{X}_h^{(r-1)})^T + b_s)$</p>
<p>$S’<em>{i,j} = \frac{exp(S</em>{i,j})}{\sum^N_{j=1}exp(S_{i,j})}$</p>
<p>其中$\mathcal{X}<em>h^{(r-1)} = (X_1,X_2,…X</em>{T_{r-1}}) \in \Bbb{R}^{N\times C_{r-1} \times T_{r-1}}$，是第$r$次的spatial-temporal block</p>
<p>$S_{i,j}$代表节点$i,j$之间的相关关系</p>
<p>$C_{r-1}$是在$r$层layer输入数据的维度，当$r=1$时，$C_0 = F$</p>
<p>$T_{r-1}$是在$r$层layer输入数据的时间维度，当$r=1$，$T_0=T_h$(recent component)</p>
<h4 id="Temporal-attention"><a href="#Temporal-attention" class="headerlink" title="Temporal attention"></a>Temporal attention</h4><p>时间注意力部分</p>
<p>$E = V_e·\sigma(((\mathcal{X}_h^{(r-1)})^TU_1)U_2(U_3\mathcal{X}_h^{(r-1)})+b_e)$</p>
<p>$E_{i,j}’ = \frac{exp(E_{i,j})}{\sum_{j=1}^{T_{r-1}}exp(E_{i,j})}$</p>
<p>$E_{i,j}$代表时间$i,j$之间的相关关系</p>
<h4 id="Spatial-Temporal-Convolution"><a href="#Spatial-Temporal-Convolution" class="headerlink" title="Spatial-Temporal Convolution"></a>Spatial-Temporal Convolution</h4><p><img src="https://i.loli.net/2021/03/17/ywtljfLhHQoIxZU.png" alt="image-20200915111531618"></p>
<h1 id="Origin-Destination-Matrix-Prediction-via-Graph-Convolution-a-New-Perspective-of-Passenger-Demand-Modeling"><a href="#Origin-Destination-Matrix-Prediction-via-Graph-Convolution-a-New-Perspective-of-Passenger-Demand-Modeling" class="headerlink" title="Origin-Destination Matrix Prediction via Graph Convolution: a New Perspective of Passenger Demand Modeling"></a>Origin-Destination Matrix Prediction via Graph Convolution: a New Perspective of Passenger Demand Modeling</h1><p>设计出租车的需求预测，即OD矩阵的预测</p>
<h2 id="Preliminaries-1"><a href="#Preliminaries-1" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><h3 id="Defintions"><a href="#Defintions" class="headerlink" title="Defintions"></a>Defintions</h3><p><strong>Grid</strong>：$G = {g_1,g_2,…g_n}$</p>
<p><strong>Time slot</strong>：${Slot_1,Slot_2,…,Slot_t}$</p>
<p><strong>OD Matrix</strong>：$M \in \Bbb{N}^{G\times G}$，其中$m_{i,j}$代表从$g_i$到$g_j$的需求量</p>
<p><strong>target</strong>：$M^{t+1} = f(M_1,M_2,…,M_{t})$</p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p><img src="https://i.loli.net/2021/03/17/v9fwdMchY2H5jPT.png" alt="image-20200916150622021"></p>
<h3 id="Grid-Embedding"><a href="#Grid-Embedding" class="headerlink" title="Grid Embedding"></a>Grid Embedding</h3><p>备注：尝试用注意力机制进行替换</p>
<h4 id="Geographical-Neighborhood"><a href="#Geographical-Neighborhood" class="headerlink" title="Geographical Neighborhood"></a>Geographical Neighborhood</h4><p>地理邻居关系：$\Phi_i = {g_j|dis(g_i,g_j)&lt;L}$，定义网格$g_i$的地理邻居节点集合</p>
<h4 id="Semantic-Neighborhood"><a href="#Semantic-Neighborhood" class="headerlink" title="Semantic Neighborhood"></a>Semantic Neighborhood</h4><p>语义上的网络而言，存在订单时候则代表两个网格之间存在语义之间的邻居关系</p>
<p>$\Omega^i_{t’} = {g_j|m_{i,j}&gt;0 || m_{j,i} &gt; 0, m_{i,j} \in M_{t’}, m_{j,i} \in M_{t’}}$</p>
<h4 id="Pre-Weighted-Aggregator-for-Grid-Embedding"><a href="#Pre-Weighted-Aggregator-for-Grid-Embedding" class="headerlink" title="Pre-Weighted Aggregator for Grid Embedding"></a>Pre-Weighted Aggregator for Grid Embedding</h4><p>此处是训练了一个聚合函数学习如何从网格的邻居节点选取特征信息</p>
<p>$v_i = \sigma(W·MEAN({v_i’}\bigcap {v_j’, g_j \in N_i}))$</p>
<p>该文提出了Pre-Weighted Aggregator，有选择性的选择更重要的邻居网格进行grid embedding</p>
<p>$r_{t’}^i = \sigma(W_g ·(f^i_{t’} + \sum_{g_j \in \Phi_i} \frac{dis(g_i,g_j)}{\sum dis(g_i,g_j)}f^j_{t’}))$  自身的特征+邻居节点的距离紧密度*邻居节点的特征</p>
<p>对于地理邻域的节点进行的属性聚合</p>
<p>$s_{t’}^i = \sigma(W_s ·(f^i_{t’} + \sum_{g_j \in \Omega_i} \frac{degree(g_i,g_j)}{\sum degree(g_i,g_j) + \epsilon}f^j_{t’}))$</p>
<p>对于语义上邻域的节点属性聚合</p>
<p>其中grid Embedding 使用的最终结果为：$v^i_{t’} = [r^i_{t’},s^i_{t’}]$</p>
<h3 id="Multi-Task-Learning"><a href="#Multi-Task-Learning" class="headerlink" title="Multi-Task Learning"></a>Multi-Task Learning</h3><p><img src="https://i.loli.net/2021/03/17/e78cmXRQWJVxoP2.png" alt="image-20200916220603834"></p>
<h4 id="Periodic-Skip-LSTM"><a href="#Periodic-Skip-LSTM" class="headerlink" title="Periodic-Skip LSTM"></a>Periodic-Skip LSTM</h4><p>$h_t =  LSTM(x_t,h_{t-1})$</p>
<p>由于仅仅利用前一个小时训练得到的特征容易有误差，所以此处采用了skip的方式</p>
<p>$h_t = LSTM(v_t^i,h^i_{t-p})$</p>
<h4 id="Main-Task-Predicting-the-OD-Matrix"><a href="#Main-Task-Predicting-the-OD-Matrix" class="headerlink" title="Main Task: Predicting the OD Matrix"></a>Main Task: Predicting the OD Matrix</h4><p>decoder： $\hat{m}_{i,j} = (W_m h_t^i)^T h_t^j$</p>
<p>Loss Function: $\mathcal{L}<em>{ODMP} = \frac{1}{|M</em>{t+1}|\times N}\sum^N_{n=1}||M_{t+1} - \hat{M}_{t+1}||$</p>
<h4 id="Two-Subtasks-Predicting-the-In-and-Out-Degress"><a href="#Two-Subtasks-Predicting-the-In-and-Out-Degress" class="headerlink" title="Two Subtasks: Predicting the In- and Out-Degress"></a>Two Subtasks: Predicting the In- and Out-Degress</h4><p>将模型分割成out和in两种流量的模式</p>
<p>$\hat{p}<em>i = w</em>{in}^Th_t^i$</p>
<p>$\hat{q}<em>i = w</em>{out}^Th_t^i$</p>
<p>$\mathcal{L}<em>{IN} = \frac{1}{|G|\times N} \sum^N</em>{n=1} \sum_{g_i \in G}(p_{i,n},\hat{p}_{i,n})^2$</p>
<p>$\mathcal{L}<em>{OUT} = \frac{1}{|G|\times N} \sum^N</em>{n=1} \sum_{g_i \in G}(q_{i,n},\hat{q}_{i,n})^2$</p>
<h4 id="Loss-Function-1"><a href="#Loss-Function-1" class="headerlink" title="Loss Function"></a>Loss Function</h4><p>$\mathcal{L}<em>{GEML} = \eta \mathcal{L}</em>{ODMP} + \eta_{in}\mathcal{L}<em>{IN} + \eta</em>{out}\mathcal{L}_{OUT}$</p>
<h4 id="Optimization-Strategy"><a href="#Optimization-Strategy" class="headerlink" title="Optimization Strategy"></a>Optimization Strategy</h4><p>采用了SGD的优化方法，其中采用了Adam的策略</p>
<h1 id="Representation-Learning-on-Graphs-Methods-and-Applications"><a href="#Representation-Learning-on-Graphs-Methods-and-Applications" class="headerlink" title="Representation Learning on Graphs: Methods and Applications"></a>Representation Learning on Graphs: Methods and Applications</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>基于图机器学习的主要目标是将图上的信息整合入机器学习模型中，embedding </p>
<p>即需要将图部分的信息编码成特征向量信息</p>
<p>学习嵌入点或者整张图在低维的映射$\Bbb{R}^d$，优化该映射从而能在embedding space反应最初图的结构信息</p>
<p>同之前图表示的区别在于，之前的图表示是利用图统计等相关手段进行图信息的预处理过程，而之后的图表示学习是将这一过程作为学习过程中的一部分</p>
<p><img src="https://i.loli.net/2021/03/17/uGPD6YROhxrkVMW.png" alt="image-20201012205948918"></p>
<p>encode node  -&gt; decode neighborhodd / decode node label</p>
<h2 id="Embedding-nodes"><a href="#Embedding-nodes" class="headerlink" title="Embedding nodes"></a>Embedding nodes</h2><h3 id="overview-of-approaches-An-encoder-decoder-perspective"><a href="#overview-of-approaches-An-encoder-decoder-perspective" class="headerlink" title="overview of approaches: An encoder-decoder perspective"></a>overview of approaches: An encoder-decoder perspective</h3><p>$$ENC: V \to \Bbb{R}^d$$</p>
<p>$$DEC: \Bbb{R}^d \times \Bbb{R}^d \to \Bbb{R}^+$$</p>
<p>目标是优化编码器和解码器映射，以最大程度地减少此重构过程中的loss</p>
<p>$$DEC(ENC(v_i), ENC(v_j)) = DEC(z_i, z_j) \approx s_\mathcal{G}(v_i, v_j) $$</p>
<p>loss function： $\mathcal{L} = \sum_{(v_i,v_j) \in \mathcal{D}} l(DEC(z_i,z_j),s_\mathcal{G}(v_i,v_j))$</p>
<p>four methodological components</p>
<ol>
<li><strong>A pairwise similarity function</strong></li>
<li><strong>An encoder function</strong></li>
<li><strong>A decoder function</strong></li>
<li><strong>A loss function</strong></li>
</ol>
<h3 id="Shallow-embedding-approaches"><a href="#Shallow-embedding-approaches" class="headerlink" title="Shallow embedding approaches"></a>Shallow embedding approaches</h3><p>大多数节点嵌入算法都依赖于我们所说的浅层嵌入。对于这些浅层嵌入方法，将节点映射到矢量嵌入的编码器功能只是一个“嵌入查找”</p>
<p>$ENC(v_i) = Zv_i$</p>
<h4 id="Factorization-based-approaches"><a href="#Factorization-based-approaches" class="headerlink" title="Factorization-based approaches"></a>Factorization-based approaches</h4><p>基于矩阵分解方法进行降维</p>
<p><strong>Laplacian eigenmaps</strong>： decoder：$DEC(z_i, z_j) = ||z_i - z_j||^2_2$</p>
<p>loss function : $\mathcal{L} = \sum_{(v_i,v_j) \in \mathcal{D}} DEC(z_i, z_j) · s_\mathcal{G}(v_i,v_j)$</p>
<p><strong>Inner-product methods</strong>：decoder： $DEC(z_i, z_j) = z_i^Tz_j$</p>
<p>loss function: $\mathcal{L} = \sum_{(v_i, v_j)\in \mathcal{D}} ||DEC(z_i,z_j) - s_\mathcal{G}(v_i, v_j)||^2_2$</p>
<h3 id="Random-walk-approaches"><a href="#Random-walk-approaches" class="headerlink" title="Random walk approaches"></a>Random walk approaches</h3><h3 id="Generalized-encoder-decoder-architectures"><a href="#Generalized-encoder-decoder-architectures" class="headerlink" title="Generalized encoder-decoder architectures"></a>Generalized encoder-decoder architectures</h3><h4 id="Neighborhood-autoencoder-methods"><a href="#Neighborhood-autoencoder-methods" class="headerlink" title="Neighborhood autoencoder methods"></a>Neighborhood autoencoder methods</h4><p><img src="https://i.loli.net/2021/03/17/UZJg6wP7DAC2FRa.png" alt="image-20201013151604019"></p>
<h4 id="Neighborhood-aggregation-and-convolutional-encoders"><a href="#Neighborhood-aggregation-and-convolutional-encoders" class="headerlink" title="Neighborhood aggregation and convolutional encoders"></a>Neighborhood aggregation and convolutional encoders</h4><p><img src="https://i.loli.net/2021/03/17/SqGXO3hHIDiolA7.png" alt="image-20201013151615833"></p>
<h2 id="Embedding-subgraphs"><a href="#Embedding-subgraphs" class="headerlink" title="Embedding subgraphs"></a>Embedding subgraphs</h2><p> <strong>Goal</strong>: encode a set of nodes and edges into a low-dimensional vector embedding </p>
<p><img src="https://i.loli.net/2021/03/17/m6BWVOoqGyQ51bL.png" alt="image-20201013151549677"></p>
<h3 id="Sets-of-node-embeddings-and-convolutional-approaches"><a href="#Sets-of-node-embeddings-and-convolutional-approaches" class="headerlink" title="Sets of node embeddings and convolutional approaches"></a>Sets of node embeddings and convolutional approaches</h3><h4 id="Sum-based-approaches"><a href="#Sum-based-approaches" class="headerlink" title="Sum-based approaches"></a>Sum-based approaches</h4><p>将节点嵌入的总和作为子图的表示</p>
<p>$z_\mathcal{S} = \sum_{v_i \in \mathcal{S}}z_i$</p>
<p>Dai等人提出的聚合方法</p>
<p>$$\eta_{i,j}^k = \sigma(W_\xi^k · COMBINE(x_i, AGGREGATE(\eta_{l,k}^{k-1}, \forall v_l \in \mathcal{N}(v_l) / v_j)))$$</p>
<p>$$z^i= \sigma(W_\mathcal{V}^k · COMBINE(x_i, AGGREGATE({\eta_{i,j}^K, \forall v_l \in \mathcal{N}(v_i)})))$$</p>
<h3 id="Graph-neutal-networks"><a href="#Graph-neutal-networks" class="headerlink" title="Graph neutal networks"></a>Graph neutal networks</h3><p> $h_i^k =   \sum_{v_j \in \mathcal{N}(v_i)}h(h_j, x_i, x_j)$</p>
<p>Li et al 提出的GRU对于GNN的改造方式</p>
<p>$$h_i^k = GRU(h_i^{k-1}, \sum_{v_j \in \mathcal{N}(v_i)}Wh_j^{k-1})$$</p>
<h1 id="GATED-GRAPH-SEQUENCE-NEURAL-NETWORKS"><a href="#GATED-GRAPH-SEQUENCE-NEURAL-NETWORKS" class="headerlink" title="GATED GRAPH SEQUENCE NEURAL NETWORKS"></a>GATED GRAPH SEQUENCE NEURAL NETWORKS</h1><p>将GNN的传播过程使用GRU进行替换，有空再看</p>
<h1 id="Graph2Seq：Graph-to-sequence-Learning-with-attention-based-neural-networks"><a href="#Graph2Seq：Graph-to-sequence-Learning-with-attention-based-neural-networks" class="headerlink" title="Graph2Seq：Graph to sequence Learning with attention-based neural networks"></a>Graph2Seq：Graph to sequence Learning with attention-based neural networks</h1><p><img src="https://i.loli.net/2021/03/17/NUHZ4BquDxnhJFO.png" alt="image-20201013173839844"></p>
<h2 id="Graph-to-Sequence-Model"><a href="#Graph-to-Sequence-Model" class="headerlink" title="Graph-to-Sequence Model"></a>Graph-to-Sequence Model</h2><h3 id="Node-embedding-generation"><a href="#Node-embedding-generation" class="headerlink" title="Node embedding generation"></a>Node embedding generation</h3><p><strong>key</strong>： 将整个过程分为三个部分，Node Embedding, Graph Embedding, Node Attention to Sequence Decoder</p>
<p>可以借鉴的地方为采用了Node Attention方法，该部分将graph embedding得到的图表示向量重新映射至$(z_0,z_1, … z_n)$的节点上，结合注意力的机制进行注意力的重新计算</p>
<p>其余后续补充</p>
<h1 id="Graph-Attention-Auto-Encoders"><a href="#Graph-Attention-Auto-Encoders" class="headerlink" title="Graph Attention Auto-Encoders"></a>Graph Attention Auto-Encoders</h1><p><img src="https://i.loli.net/2021/03/17/B5ea7xYCbOLTENM.png" alt="image-20201013210906456"></p>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>Graph attention auto-encoder 网络结构</p>
<h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>$e_{ij}^{(k)} = Sigmod(v_s^{(k)^T}\sigma(W^{(k)}h_i^{(k-1)}) + v_r^{(k)^T}\sigma(W^{(k)}h_j^{(k-1)}))$</p>
<p>$\alpha_{ij}^{(k)} = \frac{exp(e_{ij}^{(k)})}{\sum_{l\in \mathcal{N}<em>i}exp(e</em>{il}^{(k)})}$</p>
<p>${\rm h}<em>i^{(k)} = \sum</em>{j\in \mathcal{N}<em>i}\alpha^{(k)}</em>{ij}\sigma(W^{(k)}h_j^{(k-1)})$</p>
<h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>$\hat{\alpha}<em>{ij}^{(k)} = \frac{exp(\hat{e}</em>{ij}^{(k)})}{\sum_{l\in \mathcal{N}<em>i}exp(\hat{e}</em>{il}^{(k)})}$</p>
<p>$\hat{e}_{ij}^{(k)} = Sigmod(\hat{v}_s^{(k)^T}\sigma(\hat{W}^{(k)}\hat{h}_i^{(k-1)}) + \hat{v}_r^{(k)^T}\sigma(\hat{W}^{(k)}\hat{h}_j^{(k-1)}))$</p>
<p>${\rm \hat{h}}<em>i^{(k-1)} = \sum</em>{j\in \mathcal{N}<em>i}\hat{\alpha}^{(k)}</em>{ij}\sigma(\hat{W}^{(k)}\hat{h}_j^{(k)})$</p>
<h3 id="Loss-Function-2"><a href="#Loss-Function-2" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>$\sum^N_{i=1} || \rm{x_i} -\hat{x}_i ||<em>2 -\lambda\sum</em>{j\in \mathcal{N}_i} log(\frac{1}{1+exp(-h^T_ih_j)})$</p>
<p>后面的损失项是为了防止由于节点特征的相似性问题，导致没有edge节点之间的连接，减小图的结构性损失</p>
<p><strong>总结</strong>： 解码器部分，通过预测节点的特征数据，解码得到$E(v_i,v_j)$的数值，采用GAT相近的解码方式。</p>
<p>是否需要单独对解码器进行训练？</p>
]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>论文笔记</tag>
        <tag>深度学习</tag>
        <tag>交通预测</tag>
      </tags>
  </entry>
</search>
